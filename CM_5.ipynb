{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>ASSIGNMENT 1</center></h2>\n",
    "<h2><center>NAME: DEEP ASHISH JARIWALA</center></h2>\n",
    "<h2><center>SID: 20909290</center></h2>\n",
    "<h2><center>Q: CM5</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Data cleaning is the process of identifying the incorrect, incomplete, inaccurate, and missing data. It is considered a fundamental part of the machine learning model. Moreover, there will be a high effect on the model's performance metrics without a data cleaning process and can lead to an inefficient model that will yield low accuracy on the test set. For the dataset in the question, I have applied different approaches to deal with NaN values. Furthermore, for the categorical variables, one hot encoding is used for the dataset.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IRIS DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTING THE DATASET AND CHECKING THE DESCRIPTION FOR MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length    0\n",
      "sepal_width     4\n",
      "petal_length    8\n",
      "petal_width     0\n",
      "species         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"iris_dataset_missing.csv\")\n",
    "print(dataset.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REPLACING ALL THE MISSING VALUES WITH MEAN AND REMOVING OUTLIERS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>103.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5.868614</td>\n",
       "      <td>3.056778</td>\n",
       "      <td>3.814610</td>\n",
       "      <td>1.210750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.866055</td>\n",
       "      <td>0.415978</td>\n",
       "      <td>1.739788</td>\n",
       "      <td>0.789955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>4.344007</td>\n",
       "      <td>2.115481</td>\n",
       "      <td>1.033031</td>\n",
       "      <td>-0.072203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>5.182506</td>\n",
       "      <td>2.783261</td>\n",
       "      <td>1.574653</td>\n",
       "      <td>0.324021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5.743375</td>\n",
       "      <td>3.056142</td>\n",
       "      <td>4.092458</td>\n",
       "      <td>1.349398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.439874</td>\n",
       "      <td>3.237781</td>\n",
       "      <td>5.070242</td>\n",
       "      <td>1.827568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>7.795561</td>\n",
       "      <td>4.249211</td>\n",
       "      <td>6.768611</td>\n",
       "      <td>2.603123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    103.000000   103.000000    103.000000   103.000000\n",
       "mean       5.868614     3.056778      3.814610     1.210750\n",
       "std        0.866055     0.415978      1.739788     0.789955\n",
       "min        4.344007     2.115481      1.033031    -0.072203\n",
       "25%        5.182506     2.783261      1.574653     0.324021\n",
       "50%        5.743375     3.056142      4.092458     1.349398\n",
       "75%        6.439874     3.237781      5.070242     1.827568\n",
       "max        7.795561     4.249211      6.768611     2.603123"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"iris_dataset_missing.csv\")\n",
    "dataset['sepal_length'].fillna(5.858909, inplace = True)\n",
    "dataset['sepal_width'].fillna(3.059083, inplace = True)\n",
    "dataset['petal_length'].fillna(3.812370, inplace = True)\n",
    "dataset['petal_width'].fillna(1.199708, inplace = True)\n",
    "dataset = dataset[dataset['sepal_width'] >= 1.946010]\n",
    "dataset.drop(dataset[dataset['sepal_width'] > 4.3].index, inplace = True)\n",
    "dataset.describe()\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The dataset consists of 12 NaN values, which could be dropped by many methods but, for the case of the iris dataset, I have opted to replace the missing values with mean. As the dataset has very few rows, dropping the data would lead to an inefficient model. The missing data is replaced by mean using the fillna() method. Moreover, the detected outliners are also removed.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HEART DISEASE DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age          0\n",
      "sex          0\n",
      "cp           0\n",
      "trestbps     7\n",
      "chol        10\n",
      "fbs          0\n",
      "restecg      5\n",
      "thalach      4\n",
      "exang        0\n",
      "oldpeak     12\n",
      "slope        2\n",
      "ca           0\n",
      "thal         1\n",
      "target       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset_1 = pd.read_csv(\"heart_disease_missing.csv\")\n",
    "dataset_1['thal'] = dataset_1['thal'].round()\n",
    "print(dataset_1.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The dataset consists of 41 NaN values, which could be dropped or replaced depending on the type of data. For instance, the categorical variables missing can be dropped and the numeric type of data can be replaced with mean. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SEPERATING FEATURES AND LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_features = dataset_1.iloc[:,:-1]\n",
    "dataset_target = dataset_1.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONE HOT ENCODING OF CATEGORICAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_0</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>cp_2</th>\n",
       "      <th>cp_3</th>\n",
       "      <th>thal_1.0</th>\n",
       "      <th>thal_2.0</th>\n",
       "      <th>thal_3.0</th>\n",
       "      <th>slope_0.0</th>\n",
       "      <th>slope_1.0</th>\n",
       "      <th>slope_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "      <td>212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>54.311321</td>\n",
       "      <td>0.688679</td>\n",
       "      <td>0.957547</td>\n",
       "      <td>131.784610</td>\n",
       "      <td>244.133256</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0.560386</td>\n",
       "      <td>149.647978</td>\n",
       "      <td>0.344340</td>\n",
       "      <td>1.113106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476415</td>\n",
       "      <td>0.155660</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.066038</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.410377</td>\n",
       "      <td>0.070755</td>\n",
       "      <td>0.429245</td>\n",
       "      <td>0.490566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>9.145339</td>\n",
       "      <td>0.464130</td>\n",
       "      <td>1.022537</td>\n",
       "      <td>18.057222</td>\n",
       "      <td>46.444257</td>\n",
       "      <td>0.339374</td>\n",
       "      <td>0.535149</td>\n",
       "      <td>22.076206</td>\n",
       "      <td>0.476277</td>\n",
       "      <td>1.255908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500626</td>\n",
       "      <td>0.363391</td>\n",
       "      <td>0.460163</td>\n",
       "      <td>0.248936</td>\n",
       "      <td>0.231631</td>\n",
       "      <td>0.500380</td>\n",
       "      <td>0.493066</td>\n",
       "      <td>0.257022</td>\n",
       "      <td>0.496140</td>\n",
       "      <td>0.501094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.944184</td>\n",
       "      <td>126.085811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>88.032613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.185668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>119.968114</td>\n",
       "      <td>211.969594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>135.946808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.010256</td>\n",
       "      <td>241.467023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>151.939216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.726060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>139.965470</td>\n",
       "      <td>272.484222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>165.260092</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.816733</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>192.020200</td>\n",
       "      <td>406.932689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.138041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.157114</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  212.000000  212.000000  212.000000  205.000000  202.000000  212.000000   \n",
       "mean    54.311321    0.688679    0.957547  131.784610  244.133256    0.132075   \n",
       "std      9.145339    0.464130    1.022537   18.057222   46.444257    0.339374   \n",
       "min     29.000000    0.000000    0.000000   93.944184  126.085811    0.000000   \n",
       "25%     47.000000    0.000000    0.000000  119.968114  211.969594    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.010256  241.467023    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  139.965470  272.484222    0.000000   \n",
       "max     77.000000    1.000000    3.000000  192.020200  406.932689    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak  ...        cp_0  \\\n",
       "count  207.000000  208.000000  212.000000  200.000000  ...  212.000000   \n",
       "mean     0.560386  149.647978    0.344340    1.113106  ...    0.476415   \n",
       "std      0.535149   22.076206    0.476277    1.255908  ...    0.500626   \n",
       "min      0.000000   88.032613    0.000000   -0.185668  ...    0.000000   \n",
       "25%      0.000000  135.946808    0.000000    0.050778  ...    0.000000   \n",
       "50%      1.000000  151.939216    0.000000    0.726060  ...    0.000000   \n",
       "75%      1.000000  165.260092    1.000000    1.816733  ...    1.000000   \n",
       "max      2.000000  202.138041    1.000000    6.157114  ...    1.000000   \n",
       "\n",
       "             cp_1        cp_2        cp_3    thal_1.0    thal_2.0    thal_3.0  \\\n",
       "count  212.000000  212.000000  212.000000  212.000000  212.000000  212.000000   \n",
       "mean     0.155660    0.301887    0.066038    0.056604    0.528302    0.410377   \n",
       "std      0.363391    0.460163    0.248936    0.231631    0.500380    0.493066   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    1.000000    0.000000   \n",
       "75%      0.000000    1.000000    0.000000    0.000000    1.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "        slope_0.0   slope_1.0   slope_2.0  \n",
       "count  212.000000  212.000000  212.000000  \n",
       "mean     0.070755    0.429245    0.490566  \n",
       "std      0.257022    0.496140    0.501094  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    1.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.get_dummies(dataset_features['cp'], prefix = \"cp\")\n",
    "b = pd.get_dummies(dataset_features['thal'], prefix = \"thal\")\n",
    "c = pd.get_dummies(dataset_features['slope'], prefix = \"slope\")\n",
    "\n",
    "frames = [dataset_features, a, b, c]\n",
    "dataset_features = pd.concat(frames, axis = 1)\n",
    "dataset_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REPLACING NaN VALUES WITH MEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of training data:(212, 23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[76.,  0.,  2., ...,  0.,  1.,  0.],\n",
       "       [43.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [47.,  1.,  2., ...,  0.,  0.,  1.],\n",
       "       ...,\n",
       "       [54.,  1.,  2., ...,  0.,  0.,  1.],\n",
       "       [41.,  1.,  2., ...,  0.,  1.,  0.],\n",
       "       [41.,  0.,  2., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp_mean = imp_mean.fit(dataset_features)\n",
    "dataset_features = imp_mean.transform(dataset_features)\n",
    "print(f\"The shape of training data:{dataset_features.shape}\")\n",
    "dataset_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The missing values for the heart dataset is replaced by the mean of the particular column using the sklearn method SimpleImputer. This method convert the dataframe to a numpy array by replacing the missing values by mean. There are many parameter that can be varyied in SimpleImputer, the table below shows the variation of accuracy on validation set over different measures of central tendancy:</p>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Central tendency</th>\n",
    "    <th>Accuracy</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Mean</td>\n",
    "    <td>58.13%</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>Median</td>\n",
    "    <td>58.13%</td>\n",
    "  </tr>\n",
    "     <tr>\n",
    "    <td>Most frequent</td>\n",
    "    <td>60.46%</td>\n",
    "  </tr>\n",
    "   <tr>\n",
    "    <td>constant</td>\n",
    "    <td>60.46%</td>\n",
    "  </tr>   \n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
